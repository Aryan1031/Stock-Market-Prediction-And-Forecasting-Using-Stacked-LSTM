# Stock-Market-Forecasting
• Employed MinMaxScaler for data scaling, ensuring values were transformed into a normalized range between 0 and 1.

• Constructed a recurrent neural network with 4 LSTM layers, each containing 50 units, along with a dropout rate of 0.2.

• Utilized the Adam optimizer, evaluated with Mean Squared Error, resulting in an aggregate loss of 0.014 after 100 epochs.
